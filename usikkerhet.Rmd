---
title: "Usikkerhet i trafikkdata"
output: html_notebook
---

```{r setup, include = FALSE, echo = FALSE}
# Packages
library(tidyverse)
#library(flextable)

source("H:/Programmering/R/byindeks/rmd_setup.R")
# knitr options
knitr::opts_chunk$set(echo = FALSE,
                      warning = FALSE,
                      message = FALSE,
                      error = FALSE)

# Data is prepared in vehicle_register_data_prep.R
```

# Bakgrunn

Alle målinger er heftet med en grad av usikkerhet. Kilder til usikkerhet kan deles inn i to grupper:

- de som kan evalueres med statistiske metoder
- de som kan evalueres med andre metoder




# Målte størrelser i trafikkdatasammenheng
De fire viktigste størrelsene er:

- Antall kjøretøy (binomisk fordelt)
- Kjøretøylengde (kontinuerlig numerisk verdi, fasit i Kjøretøyregisteret)
- Kjøretøyfart (kontinuerlig numerisk verdi, uten fasit)
- Kjøretøyklasse (kategorisk fordelt, fasit i Kjøretøyregisteret)


## Eksempel på kombinert usikkerhet i trafikkmengdestørrelser

```{r}
# Dataloggers empiriske kombinerte usikkerhet
halvtimetrafikk <- c(12, 13, 20, 30, 50, 100, 200, 300, 200, 200, 100, 100, 75, 25)
usikkerhet_halvtime <- sqrt(sum((0.01 * halvtimetrafikk)^2))

# Ser på deteksjon som binomisk prosess
# Kan simulere 10 målinger av 100 biler (f.eks. 10 dager med 100 i døgntrafikk)
# Med dataloggers deteksjonsrate på 99 %
 rbinom(10, 100, 0.99)
```


## Hva er dataloggers "bidrag" til usikkerheten i trafikkmengdestørrelser?
For årsdøgntrafikk vil gjennomsnittet av alle årets dager naturlig nok beregnes ut fra 365 dager med varierende trafikk. Selv om registreringsutstyret hadde fungert 100 % perfekt gjennom hele året, slik at hver eneste bil ble registrert, ville ÅDT-verdien få et standardavvik som sier noe om hvor mye trafikken varierer i de 365 dagene.

I tillegg ti denne "usikkerheten" kommer det som med rette kan betegnes usikkerhet i målingen, nemlig det faktum at registreringsutstyret ikke er 100 % perfekt.

La oss tenke oss et eksempel med en trafikklenke som har nøyaktig like mange kjøretøy hver eneste dag hele året. Da kan vi beregne hvor stor usikkerheten i ÅDT blir med registreringsutstyr av ulik kvalitet.

Vi modellerer utstyrets evne til å registrere hvert kjøretøy som en binomisk prosess, det vil si at utstyret enten registrerer kjøretøyet eller så gjør det det ikke. Et perfekt utstyr ville registrere hvert kjøretøy med en sannsynlighet på 100 %. Dagens utstyr er nesten perfekt under gode forhold (fotnote), og ligger på omtrent 99 %. Utstyr som er blitt forkastet i forbindelse med testing av utstyr for rammeavtale, har hatt ned mot 90 %.

Eksempelet vi bruker er en veg med 1000 kjøretøypasseringer hver eneste dag et helt år.

```{r perfekt}
# Perfekt
registreringer_perfekt <- rbinom(365, 1000, 1)
aadt_perfekt <- mean(registreringer_perfekt)
standardavvik_perfekt <- sd(registreringer)

# Vårt krav
registreringer <- rbinom(365, 1000, 0.99) + rbinom(365, 1000, 0.001)
aadt <- mean(registreringer)
standardavvik <- sd(registreringer)

# Dårlig
registreringer_bad <- rbinom(365, 1000, 0.70) + rbinom(365, 1000, 0.01)
aadt_bad <- mean(registreringer_bad)
standardavvik_bad <- sd(registreringer)
```

Binomisk fordeling gir samme standardavvik på disse tre dataloggerne. Den tar ikke hensyn til at de kan ha ulik grad av presisjon. Sannsynligheten angir ulik grad av nøyaktighet.

Kan eventuelt legge til et ledd for falske positive, f.eks. dobbelttellinger, med lav sannsynlighet.


I testresultater bør vi oppgi utvidet usikkerhet både på punktestimater (per kjøretøy) og for aggregerte verdier (typiske intervaller på 5 min e.l.)

Hvordan finner vi utvidet usikkerhet, dvs. konfidensintervall på 95 %-nivå for de fire ulike parameterne?

Hvor skal vi sette kravet om kvalitet?

Må vurdere andre feilkilder enn de som inntreffer under ideelle forhold. Ødelagte sensorer oppstår ofte o.l.


# Mål på usikkerhet

Standardavvik for gjennomsnittet er en antagelse om standardavviket for alle beregninger av gjennomsnittet for et utvalg av samme størrelse fra samme populasjon.

Standardavviket i observasjonene er et mål på spredningen i utvalget som er gjort.

Bør alltid være presis i hva som oppgis, og alltid oppgi begge ovenstående, sammen med utvalgsstørrelsen.


# Referanser

Generelt om målinger:

- JCGM 100:2008 (Guide to the Expression of Uncertainty in Measurement) (https://www.bipm.org/en/publications/guides)
- Guidelines for Evaluating and Expressing the Uncertainty of NIST Measurement Results (https://www.nist.gov/pml/nist-technical-note-1297)
- All tests are imperfect: Accounting for false positives and false negatives using Bayesian statistics (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7082531/)



